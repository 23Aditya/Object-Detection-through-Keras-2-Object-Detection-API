{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23Aditya/Object-Detection-through-Keras-2-Object-Detection-API/blob/main/Completely_Commented_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWpu3aGV6Ivw"
      },
      "source": [
        "# Problem Statement:\n",
        "\n",
        "##### Given images of the different cigarrette packets on different aisles across different grocery stores, you have to train an object detection neural network to perform object detection on cigarrette packets of different brands so that the number of cigarrette packets of different brands can be counted and hence their availability can be tracked across different grocery stores and therefore better decisions can be taken regarding the supply chain of different brands of cigarette packets so as to ensure their continuous availability to the customer.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndvo5tMrwbKK"
      },
      "source": [
        "# Let's navigate inside the root directory of google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SED0paoUwK0S",
        "outputId": "d438a47d-934e-4e1b-8400-bf4c1c7cbc49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5hiY9iwgV9"
      },
      "source": [
        "# Let's create our directory inside google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2n5X5uawOZr",
        "outputId": "7e952a3e-c1a1-4937-e5eb-1a19f64acae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘tensorflow_od_api’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir tensorflow_od_api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWkPQd0CwtIl"
      },
      "source": [
        "# Let's navigate inside this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8uXBhT9HT0f",
        "outputId": "50ed5e2a-4817-40f7-dcec-081146bf970a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9yrlWm3wzFH"
      },
      "source": [
        "# Let's now clone the repository of Tensorflow 2 Object Detection API files inside the directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doyM4f5DIppW"
      },
      "outputs": [],
      "source": [
        "# ! git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV2m-UZ_xT9o"
      },
      "source": [
        "# Let's now follow the steps to install Tensorflow 2 Object Detection API. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAy93i8_Iw0p",
        "outputId": "d011ca9b-6265-4362-a9c8-2c1880042322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "python-tk is already the newest version (2.7.17-1~18.04).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-olefile\n",
            "  python-pkg-resources python-six python-webencodings\n",
            "Suggested packages:\n",
            "  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n",
            "  python-setuptools\n",
            "The following NEW packages will be installed:\n",
            "  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n",
            "  python-pil python-pkg-resources python-six python-webencodings\n",
            "0 upgraded, 9 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,615 kB of archives.\n",
            "After this operation, 8,916 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.6 [898 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-pil amd64 5.1.0-1ubuntu0.7 [303 kB]\n",
            "Fetched 1,615 kB in 1s (1,333 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.27)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (4.2.6)\n"
          ]
        }
      ],
      "source": [
        "! sudo apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "! pip install Cython contextlib2 pillow lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGaCtlVMJR7q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTHONPATH\"] += ':/content/models/research/:/content/models/research/slim/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2FTC1T3xgSe"
      },
      "source": [
        "# Let's now navigate inside a specific directory named \"research\" inside the installtion directory of Tensorflow 2 Object Detection API, tensorflow_od_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGAoiK2HJZhu",
        "outputId": "30519a3a-d086-4db3-9bcb-0c27f5a29c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/models/research\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/models/research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qXdIHPQJp5a"
      },
      "outputs": [],
      "source": [
        "! protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAk3RHfox0Bx"
      },
      "source": [
        "# Let's again navigate back into the root directory of google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjCGacKcJ299",
        "outputId": "b263c1d3-30e3-4b1a-ae5b-e09d59871c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhhfEzo0x7td"
      },
      "source": [
        "# Let's clone the MS COCO API repository in the root directory of google drive. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKqM9uxSJ-Py",
        "outputId": "1a7edf7c-3aaf-4fdb-9173-464cec7022e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cocoapi' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/cocodataset/cocoapi.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06vKcY03yGL7"
      },
      "source": [
        "# Let's navigate into the directory of MS COCO API. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMiIdIaWKA77",
        "outputId": "90629c32-a5fb-42d6-db97-fc26c354a49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/cocoapi/PythonAPI\n"
          ]
        }
      ],
      "source": [
        "cd cocoapi/PythonAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EucIYoyMSP"
      },
      "source": [
        "# Let's now start the installation of MS COCO API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y40q0jpAKNbp",
        "outputId": "743facbc-8c11-408f-e06e-021fd8153d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-pX47U3/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ],
      "source": [
        "! make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agOVxn1HKQrL"
      },
      "outputs": [],
      "source": [
        "cp -r pycocotools /content/drive/MyDrive/tensorflow_od_api/models/research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbIfWP00yUGr"
      },
      "source": [
        "# Let's navigate back into the \"research\" directory inside installation directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FASIFcoAKcSS",
        "outputId": "172c2f8a-8963-4fe6-a5cc-a65f65393fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/models/research\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/models/research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3udD2wXvyfzY"
      },
      "source": [
        "# Let's copy some files from this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EbQMmM9KiU0"
      },
      "outputs": [],
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lk5CuF2KqMp",
        "outputId": "3d3f976c-9b30-4900-e4e1-664c325df961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "Processing /content/drive/MyDrive/tensorflow_od_api/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.36.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.27)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 40.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 65.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 67 kB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.2 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 49.4 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.11)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1686356 sha256=afe66a8050cba7fe5eba296382a7efe2c1d4471ba992f7e301287e9f5dabc306\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-miv2xt1q/wheels/50/c9/e4/d4cc0e20db86bd98f6098e71e4082f04af8a07de0cbe30a432\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=e6965f67d3ba35cc884bd5845de1372f8655f5ff0546d937f120fa1d444f42b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=a044cc352847bba74f7dc4c42c08a01527272008b99765b7e0972c5905c3977b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=10c87c67a9d6e2661edeb1ec5db7b80533ea097fabd7c7b7a935f913a02c5ea8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a1906db419ad26d90f83f8220874d2c52246a4ec4583183c46b78d6426910b34\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.1\n",
            "    Uninstalling pymongo-4.0.1:\n",
            "      Successfully uninstalled pymongo-4.0.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.36.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.7 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.1 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"
          ]
        }
      ],
      "source": [
        "! python -m pip install --use-feature=2020-resolver ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69p_mG9myuwY"
      },
      "source": [
        "# Let's now check that whether the installtion of our Tensorflow 2 Object Detection API is successful or not. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4aiHm9gKuir",
        "outputId": "f5d4e634-7cce-46fc-f15b-2f6e243470d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-02-20 08:38:08.465356: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W0220 08:38:08.909864 140179537106816 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.74s\n",
            "I0220 08:38:09.209871 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.62s\n",
            "I0220 08:38:09.833211 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.62s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n",
            "I0220 08:38:10.145704 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n",
            "I0220 08:38:10.438955 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.24s\n",
            "I0220 08:38:12.675028 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0220 08:38:12.676156 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0220 08:38:12.702554 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0220 08:38:12.719183 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0220 08:38:12.737183 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "I0220 08:38:12.855184 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "I0220 08:38:12.970693 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "I0220 08:38:13.089043 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I0220 08:38:13.201912 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "I0220 08:38:13.311593 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0220 08:38:13.348726 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0220 08:38:13.532147 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0220 08:38:13.532418 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0220 08:38:13.532545 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0220 08:38:13.536068 140179537106816 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0220 08:38:13.553519 140179537106816 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0220 08:38:13.553658 140179537106816 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0220 08:38:13.615639 140179537106816 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0220 08:38:13.615816 140179537106816 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0220 08:38:13.776056 140179537106816 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0220 08:38:13.776251 140179537106816 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0220 08:38:13.935928 140179537106816 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0220 08:38:13.936126 140179537106816 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0220 08:38:14.198120 140179537106816 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0220 08:38:14.198327 140179537106816 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0220 08:38:14.466782 140179537106816 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0220 08:38:14.466974 140179537106816 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0220 08:38:15.026780 140179537106816 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0220 08:38:15.026953 140179537106816 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0220 08:38:15.132570 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0220 08:38:15.186503 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:15.245930 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0220 08:38:15.246105 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0220 08:38:15.246183 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0220 08:38:15.247807 140179537106816 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0220 08:38:15.263279 140179537106816 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0220 08:38:15.263393 140179537106816 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0220 08:38:15.397075 140179537106816 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0220 08:38:15.397269 140179537106816 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0220 08:38:15.634027 140179537106816 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0220 08:38:15.634235 140179537106816 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0220 08:38:15.871148 140179537106816 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0220 08:38:15.871371 140179537106816 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0220 08:38:16.218982 140179537106816 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0220 08:38:16.219170 140179537106816 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0220 08:38:16.575642 140179537106816 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0220 08:38:16.575838 140179537106816 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0220 08:38:17.049141 140179537106816 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0220 08:38:17.049324 140179537106816 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0220 08:38:17.265667 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0220 08:38:17.329912 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:17.400775 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0220 08:38:17.400996 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0220 08:38:17.401098 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0220 08:38:17.404010 140179537106816 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0220 08:38:17.424146 140179537106816 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0220 08:38:17.424307 140179537106816 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0220 08:38:17.546707 140179537106816 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0220 08:38:17.546900 140179537106816 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0220 08:38:17.792290 140179537106816 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0220 08:38:17.792481 140179537106816 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0220 08:38:18.041665 140179537106816 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0220 08:38:18.041863 140179537106816 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0220 08:38:18.405359 140179537106816 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0220 08:38:18.405644 140179537106816 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0220 08:38:18.778145 140179537106816 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0220 08:38:18.778358 140179537106816 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0220 08:38:19.294030 140179537106816 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0220 08:38:19.294227 140179537106816 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I0220 08:38:19.548791 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I0220 08:38:19.607695 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:19.679682 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0220 08:38:19.679871 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0220 08:38:19.679934 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0220 08:38:19.681808 140179537106816 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0220 08:38:19.699128 140179537106816 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0220 08:38:19.699291 140179537106816 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0220 08:38:20.071243 140179537106816 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0220 08:38:20.071438 140179537106816 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0220 08:38:20.329295 140179537106816 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0220 08:38:20.329491 140179537106816 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0220 08:38:20.583051 140179537106816 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0220 08:38:20.583257 140179537106816 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0220 08:38:21.042854 140179537106816 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0220 08:38:21.043053 140179537106816 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0220 08:38:21.538119 140179537106816 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0220 08:38:21.538320 140179537106816 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0220 08:38:22.155378 140179537106816 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0220 08:38:22.155675 140179537106816 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I0220 08:38:22.393796 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I0220 08:38:22.464638 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:22.546196 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0220 08:38:22.546384 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0220 08:38:22.546442 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0220 08:38:22.548092 140179537106816 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0220 08:38:22.564027 140179537106816 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0220 08:38:22.564152 140179537106816 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0220 08:38:22.688474 140179537106816 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0220 08:38:22.688659 140179537106816 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0220 08:38:23.036808 140179537106816 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0220 08:38:23.036990 140179537106816 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0220 08:38:23.390340 140179537106816 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0220 08:38:23.390539 140179537106816 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0220 08:38:23.934998 140179537106816 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0220 08:38:23.935184 140179537106816 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0220 08:38:24.505159 140179537106816 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0220 08:38:24.505361 140179537106816 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0220 08:38:25.415720 140179537106816 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0220 08:38:25.415919 140179537106816 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I0220 08:38:25.700166 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I0220 08:38:25.775147 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:26.098662 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0220 08:38:26.098867 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0220 08:38:26.098951 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0220 08:38:26.101005 140179537106816 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0220 08:38:26.119917 140179537106816 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0220 08:38:26.120114 140179537106816 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0220 08:38:26.336544 140179537106816 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0220 08:38:26.336754 140179537106816 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0220 08:38:26.797277 140179537106816 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0220 08:38:26.797492 140179537106816 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0220 08:38:27.271545 140179537106816 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0220 08:38:27.271755 140179537106816 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0220 08:38:27.946403 140179537106816 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0220 08:38:27.946625 140179537106816 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0220 08:38:28.669424 140179537106816 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0220 08:38:28.669656 140179537106816 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0220 08:38:29.810990 140179537106816 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0220 08:38:29.811226 140179537106816 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I0220 08:38:30.320097 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I0220 08:38:30.401810 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:30.505225 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0220 08:38:30.505430 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0220 08:38:30.505536 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0220 08:38:30.507446 140179537106816 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0220 08:38:30.524755 140179537106816 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0220 08:38:30.524949 140179537106816 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0220 08:38:30.752712 140179537106816 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0220 08:38:30.752924 140179537106816 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0220 08:38:31.292597 140179537106816 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0220 08:38:31.292814 140179537106816 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0220 08:38:31.850988 140179537106816 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0220 08:38:31.851214 140179537106816 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0220 08:38:32.640168 140179537106816 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0220 08:38:32.640391 140179537106816 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0220 08:38:33.846954 140179537106816 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0220 08:38:33.847183 140179537106816 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0220 08:38:35.273046 140179537106816 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0220 08:38:35.273252 140179537106816 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I0220 08:38:35.811648 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I0220 08:38:35.899014 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0220 08:38:36.014403 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0220 08:38:36.014609 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0220 08:38:36.014674 140179537106816 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0220 08:38:36.016482 140179537106816 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0220 08:38:36.033996 140179537106816 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0220 08:38:36.034182 140179537106816 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0220 08:38:36.323670 140179537106816 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0220 08:38:36.323879 140179537106816 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0220 08:38:36.974638 140179537106816 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0220 08:38:36.974849 140179537106816 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0220 08:38:37.620927 140179537106816 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0220 08:38:37.621136 140179537106816 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0220 08:38:38.626573 140179537106816 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0220 08:38:38.626778 140179537106816 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0220 08:38:39.710819 140179537106816 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0220 08:38:39.711048 140179537106816 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0220 08:38:41.533217 140179537106816 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0220 08:38:41.533427 140179537106816 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I0220 08:38:42.656821 140179537106816 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I0220 08:38:42.750799 140179537106816 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.54s\n",
            "I0220 08:38:42.890302 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 29.54s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0220 08:38:42.898190 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0220 08:38:42.900224 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0220 08:38:42.900827 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0220 08:38:42.902569 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0220 08:38:42.904129 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0220 08:38:42.904647 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0220 08:38:42.905759 140179537106816 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 34.437s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "! python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCkN3vNIzKq3"
      },
      "source": [
        "# The \"OK\" at the end signifies that the installation of our Tensorflow 2 Object Detection API has been successful. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYZ2xDdRL6DE"
      },
      "source": [
        "# As you can see above the installation of Tensorflow 2 Object Detection API has been succeeded. Now, we have to train our desired neural network model to detect objects in images of our dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjI9smUEMazl"
      },
      "source": [
        "# So firstly, please navigate to the installtion directory of the API.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtA08S3aLbBL",
        "outputId": "f294693f-da15-4137-da92-5dbb10f50018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G6SEcGgz9QC"
      },
      "source": [
        "# Let's first create a directory named \"workspace\" inside our navigated directory of installation. In this directory of \"workspace\", we will be saving the training configurations of different neural network archirectures on different datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B9_TA970VNg",
        "outputId": "752f0818-033f-4ca6-a7d9-7c514956cded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘workspace’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8UFuBqg0dBL"
      },
      "source": [
        "# Now, inside this workspace directory, we will be creating the directories for training configurations on different datasets. A different dataset will be having different directory. Now, because we will be here performing object detection on shelf images, so let's create a directory named \"shelf_objects_detection\" inside this directory (workspace). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4kTByVf1IHB",
        "outputId": "74190dfa-f7b9-4771-93b5-b10bb8bfdc0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/workspace\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3mzDiXb1NG0",
        "outputId": "958e0e3f-633d-4faf-88d6-0b66907dbaba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘shelf_objects_detection’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir shelf_objects_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfauhe31WhL"
      },
      "source": [
        "# Now, every such directory will consist of all the details of training configurations related to object detection for a specific dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYfjU_kH1kiq"
      },
      "source": [
        "# Let's create a directory inside \"shelf_objects_detection\", named \"images\" inside which we will be downloading our training as well as testing datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDC1hGG719C3",
        "outputId": "3c86be5d-041e-466b-900a-45d57ae85b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99wvaOH-2Faa",
        "outputId": "b05e6806-3651-4160-a511-ad4c1b6168f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘images’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs9hAXIJ2Nxe"
      },
      "source": [
        "# Now, let's download our dataset into this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b2jOiw2V60",
        "outputId": "67cb5730-67b4-49d3-a42b-be24ff330622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/images\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8PR28_022-m",
        "outputId": "a8e95901-6d11-4aee-8e52-b50a4aac8cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-02-20 08:38:44--  https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.70.128, 74.125.201.128, 173.194.193.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.70.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580345649 (553M) [application/gzip]\n",
            "Saving to: ‘ShelfImages.tar.gz.2’\n",
            "\n",
            "ShelfImages.tar.gz. 100%[===================>] 553.46M  28.4MB/s    in 13s     \n",
            "\n",
            "2022-02-20 08:38:57 (43.5 MB/s) - ‘ShelfImages.tar.gz.2’ saved [580345649/580345649]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadov9cAMjuK"
      },
      "source": [
        "# Now, let's unzip the dataset into this directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rhVdLRYLudN",
        "outputId": "2e5653db-93d6-4978-f5b2-8e9a0c722462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ShelfImages/train/C2_P06_N2_S3_1.JPG\n",
            "ShelfImages/train/C3_P06_N3_S4_2.JPG\n",
            "ShelfImages/train/C3_P07_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P01_N4_S2_1.JPG\n",
            "ShelfImages/train/C1_P04_N3_S2_1.JPG\n",
            "ShelfImages/test/C1_P05_N4_S3_1.JPG\n",
            "ShelfImages/train/C1_P09_N3_S3_1.JPG\n",
            "ShelfImages/test/C1_P12_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P01_N3_S3_1.JPG\n",
            "ShelfImages/train/C1_P06_N2_S3_2.JPG\n",
            "ShelfImages/train/C2_P08_N2_S3_1.JPG\n",
            "ShelfImages/train/C3_P06_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P07_N1_S3_3.JPG\n",
            "ShelfImages/train/C3_P02_N3_S3_1.JPG\n",
            "ShelfImages/train/C2_P03_N2_S2_1.JPG\n",
            "ShelfImages/train/C3_P01_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P02_N4_S2_1.JPG\n",
            "ShelfImages/train/C4_P02_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P12_N3_S4_1.JPG\n",
            "ShelfImages/train/C3_P06_N3_S3_1.JPG\n",
            "ShelfImages/test/C4_P04_N2_S2_1.JPG\n",
            "ShelfImages/train/C4_P08_N1_S2_1.JPG\n",
            "ShelfImages/train/C4_P04_N2_S4_1.JPG\n",
            "ShelfImages/test/C1_P05_N2_S4_2.JPG\n",
            "ShelfImages/train/C1_P06_N2_S3_3.JPG\n",
            "ShelfImages/train/C2_P08_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P01_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P06_N1_S3_2.JPG\n",
            "ShelfImages/train/C2_P04_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P07_N3_S3_1.JPG\n",
            "ShelfImages/train/C3_P02_N2_S3_1.JPG\n",
            "ShelfImages/train/C2_P06_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P07_N1_S5_1.JPG\n",
            "ShelfImages/train/C1_P03_N1_S2_2.JPG\n",
            "ShelfImages/train/C2_P02_N3_S2_1.JPG\n",
            "ShelfImages/train/C2_P03_N1_S2_1.JPG\n",
            "ShelfImages/train/C2_P01_N1_S2_1.JPG\n",
            "ShelfImages/train/C4_P02_N4_S3_1.JPG\n",
            "ShelfImages/train/C3_P06_N2_S3_1.JPG\n",
            "ShelfImages/test/C4_P07_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P07_N2_S4_1.JPG\n",
            "ShelfImages/train/C4_P05_N1_S5_1.JPG\n",
            "ShelfImages/train/C2_P08_N2_S3_2.JPG\n",
            "ShelfImages/train/C1_P10_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P12_N2_S4_1.JPG\n",
            "ShelfImages/test/C1_P08_N2_S4_1.JPG\n",
            "ShelfImages/train/C4_P04_N1_S4_1.JPG\n",
            "ShelfImages/train/C3_P04_N2_S3_1.JPG\n",
            "ShelfImages/train/C1_P01_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P02_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P02_N4_S2_1.JPG\n",
            "ShelfImages/train/C4_P01_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P01_N2_S2_1.JPG\n",
            "ShelfImages/test/C1_P02_N2_S2_1.JPG\n",
            "ShelfImages/test/C2_P02_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P06_N1_S3_2.JPG\n",
            "ShelfImages/train/C4_P04_N3_S3_1.JPG\n",
            "ShelfImages/train/C2_P08_N1_S3_2.JPG\n",
            "ShelfImages/train/C3_P04_N4_S2_1.JPG\n",
            "ShelfImages/test/C3_P03_N2_S4_1.JPG\n",
            "ShelfImages/train/C2_P07_N2_S3_1.JPG\n",
            "ShelfImages/test/C2_P05_N3_S3_1.JPG\n",
            "ShelfImages/test/C2_P01_N3_S3_1.JPG\n",
            "ShelfImages/train/C3_P07_N1_S4_1.JPG\n",
            "ShelfImages/test/C1_P12_N1_S2_1.JPG\n",
            "ShelfImages/train/C1_P10_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P12_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P02_N2_S2_1.JPG\n",
            "ShelfImages/train/C4_P05_N2_S4_1.JPG\n",
            "ShelfImages/train/C3_P06_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P04_N1_S3_1.JPG\n",
            "ShelfImages/\n",
            "ShelfImages/train/C4_P03_N2_S4_1.JPG\n",
            "ShelfImages/test/C1_P03_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P04_N2_S3_1.JPG\n",
            "ShelfImages/train/C1_P05_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P01_N1_S2_1.JPG\n",
            "ShelfImages/test/C4_P07_N1_S3_2.JPG\n",
            "ShelfImages/train/C3_P05_N3_S3_1.JPG\n",
            "ShelfImages/test/C1_P08_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P07_N2_S4_1.JPG\n",
            "ShelfImages/train/C3_P07_N3_S3_1.JPG\n",
            "ShelfImages/train/C3_P04_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P10_N3_S3_1.JPG\n",
            "ShelfImages/test/C1_P06_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P02_N2_S3_1.JPG\n",
            "ShelfImages/train/C3_P02_N3_S2_1.JPG\n",
            "ShelfImages/test/C2_P03_N2_S3_1.JPG\n",
            "ShelfImages/test/C1_P03_N3_S2_1.JPG\n",
            "ShelfImages/train/C3_P01_N2_S2_2.JPG\n",
            "ShelfImages/train/C2_P07_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P04_N1_S2_1.JPG\n",
            "ShelfImages/train/C2_P07_N3_S2_1.JPG\n",
            "ShelfImages/train/C2_P06_N1_S2_1.JPG\n",
            "ShelfImages/train/C2_P02_N1_S2_1.JPG\n",
            "ShelfImages/train/C3_P07_N5_S2_1.JPG\n",
            "ShelfImages/test/C3_P03_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P05_N1_S4_1.JPG\n",
            "ShelfImages/train/C3_P04_N4_S2_2.JPG\n",
            "ShelfImages/train/C3_P04_N2_S2_1.JPG\n",
            "ShelfImages/train/C4_P08_N1_S5_1.JPG\n",
            "ShelfImages/train/C4_P07_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P11_N2_S4_1.JPG\n",
            "ShelfImages/train/C3_P05_N2_S3_1.JPG\n",
            "ShelfImages/train/C2_P09_N1_S7_1.JPG\n",
            "ShelfImages/train/C1_P09_N2_S6_1.JPG\n",
            "ShelfImages/train/C3_P07_N2_S3_1.JPG\n",
            "ShelfImages/train/C4_P02_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P04_N1_S3_2.JPG\n",
            "ShelfImages/train/C3_P03_N4_S2_1.JPG\n",
            "ShelfImages/train/C1_P08_N2_S5_1.JPG\n",
            "ShelfImages/train/C3_P02_N2_S2_1.JPG\n",
            "ShelfImages/train/C3_P01_N1_S2_2.JPG\n",
            "ShelfImages/train/C1_P09_N1_S2_1.JPG\n",
            "ShelfImages/train/C2_P01_N1_S5_1.JPG\n",
            "ShelfImages/test/C1_P03_N2_S2_1.JPG\n",
            "ShelfImages/train/C1_P01_N2_S4_1.JPG\n",
            "ShelfImages/train/C2_P03_N1_S5_1.JPG\n",
            "ShelfImages/train/C4_P05_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P03_N3_S3_1.JPG\n",
            "ShelfImages/train/C3_P07_N4_S2_1.JPG\n",
            "ShelfImages/train/C3_P05_N4_S2_1.JPG\n",
            "ShelfImages/train/C3_P02_N3_S2_2.JPG\n",
            "ShelfImages/train/C4_P02_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P11_N1_S4_1.JPG\n",
            "ShelfImages/train/C3_P07_N1_S3_1.JPG\n",
            "ShelfImages/test/C4_P03_N1_S4_1.JPG\n",
            "ShelfImages/train/C3_P05_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P05_N2_S2_1.JPG\n",
            "ShelfImages/train/C3_P04_N1_S2_1.JPG\n",
            "ShelfImages/train/C4_P05_N5_S2_1.JPG\n",
            "ShelfImages/train/C2_P02_N1_S5_1.JPG\n",
            "ShelfImages/test/C1_P06_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P05_N2_S3_1.JPG\n",
            "ShelfImages/train/C1_P04_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P02_N1_S2_1.JPG\n",
            "ShelfImages/test/C4_P08_N2_S2_1.JPG\n",
            "ShelfImages/test/C1_P10_N1_S5_1.JPG\n",
            "ShelfImages/test/C1_P03_N1_S2_1.JPG\n",
            "ShelfImages/test/C3_P06_N4_S3_1.JPG\n",
            "ShelfImages/train/C4_P08_N2_S4_1.JPG\n",
            "ShelfImages/train/C4_P03_N2_S3_1.JPG\n",
            "ShelfImages/train/C2_P09_N1_S7_2.JPG\n",
            "ShelfImages/train/C4_P07_N1_S4_2.JPG\n",
            "ShelfImages/train/C3_P07_N3_S2_1.JPG\n",
            "ShelfImages/train/C3_P03_N3_S2_1.JPG\n",
            "ShelfImages/test/C1_P12_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P02_N2_S2_2.JPG\n",
            "ShelfImages/train/C2_P04_N1_S5_1.JPG\n",
            "ShelfImages/train/C4_P02_N1_S3_2.JPG\n",
            "ShelfImages/test/C3_P04_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P05_N1_S2_1.JPG\n",
            "ShelfImages/train/C2_P01_N1_S5_2.JPG\n",
            "ShelfImages/test/C3_P03_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P07_N1_S2_1.JPG\n",
            "ShelfImages/train/C4_P06_N4_S3_1.JPG\n",
            "ShelfImages/test/C2_P01_N2_S2_1.JPG\n",
            "ShelfImages/train/C2_P01_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P01_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P03_N3_S3_2.JPG\n",
            "ShelfImages/test/C1_P02_N1_S5_1.JPG\n",
            "ShelfImages/train/C4_P05_N4_S2_1.JPG\n",
            "ShelfImages/test/C2_P08_N3_S3_2.JPG\n",
            "ShelfImages/train/C1_P04_N2_S4_1.JPG\n",
            "ShelfImages/train/C4_P06_N1_S4_1.JPG\n",
            "ShelfImages/train/C3_P03_N2_S2_1.JPG\n",
            "ShelfImages/train/C1_P11_N2_S3_1.JPG\n",
            "ShelfImages/test/C3_P01_N2_S3_2.JPG\n",
            "ShelfImages/train/C4_P05_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P07_N2_S2_1.JPG\n",
            "ShelfImages/train/C3_P05_N2_S2_1.JPG\n",
            "ShelfImages/train/C1_P04_N1_S5_2.JPG\n",
            "ShelfImages/train/C2_P06_N1_S5_1.JPG\n",
            "ShelfImages/train/C1_P02_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P12_N4_S3_1.JPG\n",
            "ShelfImages/train/C1_P01_N2_S3_1.JPG\n",
            "ShelfImages/train/C4_P03_N2_S3_2.JPG\n",
            "ShelfImages/train/C1_P09_N4_S4_1.JPG\n",
            "ShelfImages/train/C4_P05_N3_S2_1.JPG\n",
            "ShelfImages/train/C2_P05_N2_S5_1.JPG\n",
            "ShelfImages/test/C2_P04_N3_S2_1.JPG\n",
            "ShelfImages/train/C2_P04_N3_S4_1.JPG\n",
            "ShelfImages/train/C3_P03_N1_S2_1.JPG\n",
            "ShelfImages/train/C4_P04_N5_S2_1.JPG\n",
            "ShelfImages/train/C3_P07_N1_S2_1.JPG\n",
            "ShelfImages/train/C3_P01_N1_S5_2.JPG\n",
            "ShelfImages/train/C1_P09_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P05_N1_S2_1.JPG\n",
            "ShelfImages/train/C1_P01_N4_S2_1.JPG\n",
            "ShelfImages/train/C1_P05_N3_S4_1.JPG\n",
            "ShelfImages/train/C1_P02_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P12_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P08_N2_S3_1.JPG\n",
            "ShelfImages/train/C1_P01_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P06_N2_S3_1.JPG\n",
            "ShelfImages/train/C2_P07_N1_S6_2.JPG\n",
            "ShelfImages/train/C3_P07_N1_S6_1.JPG\n",
            "ShelfImages/train/C1_P09_N3_S4_1.JPG\n",
            "ShelfImages/train/C2_P02_N2_S4_1.JPG\n",
            "ShelfImages/train/C3_P02_N1_S5_1.JPG\n",
            "ShelfImages/train/C2_P04_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P02_N3_S3_1.JPG\n",
            "ShelfImages/train/C4_P08_N3_S3_2.JPG\n",
            "ShelfImages/train/C1_P01_N3_S2_1.JPG\n",
            "ShelfImages/train/C3_P03_N1_S5_1.JPG\n",
            "ShelfImages/train/C2_P08_N1_S6_1.JPG\n",
            "ShelfImages/test/C3_P06_N2_S3_2.JPG\n",
            "ShelfImages/train/C1_P04_N2_S3_1.JPG\n",
            "ShelfImages/train/C4_P06_N1_S3_1.JPG\n",
            "ShelfImages/train/C1_P11_N1_S3_2.JPG\n",
            "ShelfImages/train/C1_P09_N1_S5_2.JPG\n",
            "ShelfImages/train/C2_P05_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P03_N1_S2_2.JPG\n",
            "ShelfImages/train/C1_P05_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P09_N2_S4_1.JPG\n",
            "ShelfImages/train/C4_P01_N1_S2_1.JPG\n",
            "ShelfImages/train/C1_P06_N1_S4_2.JPG\n",
            "ShelfImages/train/C2_P04_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P08_N4_S4_1.JPG\n",
            "ShelfImages/train/C4_P08_N2_S3_2.JPG\n",
            "ShelfImages/train/C1_P12_N4_S2_1.JPG\n",
            "ShelfImages/train/C1_P01_N1_S3_2.JPG\n",
            "ShelfImages/train/C1_P02_N4_S2_1.JPG\n",
            "ShelfImages/test/C4_P02_N4_S2_1.JPG\n",
            "ShelfImages/train/C1_P01_N2_S2_1.JPG\n",
            "ShelfImages/train/C2_P05_N2_S3_1.JPG\n",
            "ShelfImages/train/C1_P09_N3_S4_2.JPG\n",
            "ShelfImages/test/C1_P10_N2_S3_1.JPG\n",
            "ShelfImages/test/C3_P06_N1_S3_2.JPG\n",
            "ShelfImages/train/C3_P02_N2_S4_1.JPG\n",
            "ShelfImages/test/C4_P04_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P02_N3_S3_1.JPG\n",
            "ShelfImages/train/C1_P04_N4_S2_1.JPG\n",
            "ShelfImages/test/\n",
            "ShelfImages/train/C2_P07_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P05_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P05_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P04_N1_S3_1.JPG\n",
            "ShelfImages/train/C1_P10_N3_S2_1.JPG\n",
            "ShelfImages/train/C2_P07_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P02_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P07_N2_S3_1.JPG\n",
            "ShelfImages/train/C2_P08_N1_S6_2.JPG\n",
            "ShelfImages/train/C1_P12_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P02_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P08_N3_S4_1.JPG\n",
            "ShelfImages/train/C1_P01_N1_S2_1.JPG\n",
            "ShelfImages/train/C1_P07_N2_S3_1.JPG\n",
            "ShelfImages/train/C3_P05_N1_S5_1.JPG\n",
            "ShelfImages/test/C2_P07_N2_S2_1.JPG\n",
            "ShelfImages/train/C1_P05_N3_S3_1.JPG\n",
            "ShelfImages/train/C2_P03_N2_S4_1.JPG\n",
            "ShelfImages/test/C1_P10_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P07_N3_S3_2.JPG\n",
            "ShelfImages/test/C1_P06_N1_S5_1.JPG\n",
            "ShelfImages/train/C3_P02_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P02_N2_S3_1.JPG\n",
            "ShelfImages/test/C4_P08_N1_S5_2.JPG\n",
            "ShelfImages/test/C1_P03_N1_S4_1.JPG\n",
            "ShelfImages/test/C1_P11_N2_S4_2.JPG\n",
            "ShelfImages/train/C2_P05_N1_S4_1.JPG\n",
            "ShelfImages/test/C3_P05_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P10_N2_S2_1.JPG\n",
            "ShelfImages/train/C1_P12_N2_S2_1.JPG\n",
            "ShelfImages/train/C2_P01_N1_S3_1.JPG\n",
            "ShelfImages/train/C4_P04_N1_S2_1.JPG\n",
            "ShelfImages/train/C1_P05_N1_S4_2.JPG\n",
            "ShelfImages/train/C1_P05_N2_S3_1.JPG\n",
            "ShelfImages/test/C3_P01_N1_S5_1.JPG\n",
            "ShelfImages/train/C2_P03_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P04_N1_S3_2.JPG\n",
            "ShelfImages/train/C4_P07_N2_S3_2.JPG\n",
            "ShelfImages/train/C2_P06_N3_S3_1.JPG\n",
            "ShelfImages/train/C1_P10_N3_S2_2.JPG\n",
            "ShelfImages/test/C4_P08_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P08_N3_S4_2.JPG\n",
            "ShelfImages/test/C1_P11_N1_S4_2.JPG\n",
            "ShelfImages/train/C1_P01_N1_S2_2.JPG\n",
            "ShelfImages/train/C1_P08_N4_S3_1.JPG\n",
            "ShelfImages/train/C2_P06_N3_S4_1.JPG\n",
            "ShelfImages/train/C3_P01_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P10_N1_S2_1.JPG\n",
            "ShelfImages/test/C2_P07_N1_S6_1.JPG\n",
            "ShelfImages/test/C4_P03_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P05_N2_S4_1.JPG\n",
            "ShelfImages/train/C2_P03_N3_S3_1.JPG\n",
            "ShelfImages/test/C1_P03_N2_S3_1.JPG\n",
            "ShelfImages/test/C3_P02_N1_S2_2.JPG\n",
            "ShelfImages/train/C3_P01_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P08_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P04_N2_S2_1.JPG\n",
            "ShelfImages/test/C1_P11_N2_S4_3.JPG\n",
            "ShelfImages/test/C1_P03_N1_S4_2.JPG\n",
            "ShelfImages/train/C1_P05_N1_S3_1.JPG\n",
            "ShelfImages/test/C2_P01_N1_S4_1.JPG\n",
            "ShelfImages/test/C4_P08_N3_S3_1.JPG\n",
            "ShelfImages/train/C1_P07_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P05_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P02_N1_S2_1.JPG\n",
            "ShelfImages/train/C2_P08_N2_S4_1.JPG\n",
            "ShelfImages/train/C3_P01_N4_S3_1.JPG\n",
            "ShelfImages/train/C1_P08_N2_S4_2.JPG\n",
            "ShelfImages/train/C1_P05_N1_S4_3.JPG\n",
            "ShelfImages/train/C3_P06_N1_S5_1.JPG\n",
            "ShelfImages/train/C2_P06_N2_S4_1.JPG\n",
            "ShelfImages/test/C1_P11_N1_S3_1.JPG\n",
            "ShelfImages/train/C1_P11_N1_S5_1.JPG\n",
            "ShelfImages/train/C1_P07_N2_S3_2.JPG\n",
            "ShelfImages/train/C1_P03_N2_S3_2.JPG\n",
            "ShelfImages/train/C2_P01_N2_S3_1.JPG\n",
            "ShelfImages/train/C3_P03_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P04_N2_S3_1.JPG\n",
            "ShelfImages/test/C1_P04_N1_S4_1.JPG\n",
            "ShelfImages/test/C1_P06_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P03_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P03_N1_S3_2.JPG\n",
            "ShelfImages/train/C4_P05_N1_S2_1.JPG\n",
            "ShelfImages/test/C1_P11_N2_S3_2.JPG\n",
            "ShelfImages/train/C2_P08_N4_S3_1.JPG\n",
            "ShelfImages/train/C3_P06_N3_S4_1.JPG\n",
            "ShelfImages/train/C4_P01_N2_S4_1.JPG\n",
            "ShelfImages/train/C2_P08_N1_S4_1.JPG\n",
            "ShelfImages/train/C2_P05_N3_S3_2.JPG\n",
            "ShelfImages/test/C4_P01_N2_S2_1.JPG\n",
            "ShelfImages/test/C4_P05_N2_S2_1.JPG\n",
            "ShelfImages/train/C2_P03_N4_S2_1.JPG\n",
            "ShelfImages/train/C2_P01_N4_S2_1.JPG\n",
            "ShelfImages/test/C3_P04_N1_S5_1.JPG\n",
            "ShelfImages/train/C1_P08_N2_S3_1.JPG\n",
            "ShelfImages/test/C1_P04_N3_S3_1.JPG\n",
            "ShelfImages/train/C2_P06_N1_S4_1.JPG\n",
            "ShelfImages/train/C1_P06_N2_S3_1.JPG\n",
            "ShelfImages/train/C2_P05_N1_S3_1.JPG\n",
            "ShelfImages/train/C1_P05_N1_S3_2.JPG\n",
            "ShelfImages/train/C1_P07_N1_S3_2.JPG\n",
            "ShelfImages/train/C4_P04_N1_S5_1.JPG\n",
            "ShelfImages/test/C4_P04_N4_S2_1.JPG\n",
            "ShelfImages/train/C2_P03_N1_S3_1.JPG\n",
            "ShelfImages/train/C3_P04_N2_S4_1.JPG\n",
            "ShelfImages/train/C1_P06_N3_S3_2.JPG\n",
            "ShelfImages/train/C2_P01_N3_S2_1.JPG\n",
            "ShelfImages/train/C1_P09_N4_S3_1.JPG\n",
            "ShelfImages/test/C1_P12_N2_S3_1.JPG\n",
            "ShelfImages/train/C1_P12_N2_S5_1.JPG\n",
            "ShelfImages/train/\n",
            "ShelfImages/train/C2_P06_N2_S4_2.JPG\n",
            "ShelfImages/test/C4_P08_N1_S3_1.JPG\n",
            "ShelfImages/train/C2_P08_N3_S3_1.JPG\n",
            "ShelfImages/train/C2_P04_N3_S3_1.JPG\n",
            "ShelfImages/train/C1_P07_N2_S3_3.JPG\n",
            "ShelfImages/train/C2_P01_N2_S3_2.JPG\n",
            "ShelfImages/train/C2_P05_N2_S3_2.JPG\n",
            "ShelfImages/train/C3_P01_N2_S3_1.JPG\n",
            "ShelfImages/train/C3_P03_N2_S3_1.JPG\n",
            "ShelfImages/test/C2_P02_N1_S4_1.JPG\n",
            "ShelfImages/test/C1_P02_N2_S3_1.JPG\n",
            "ShelfImages/test/C4_P07_N3_S3_1.JPG\n"
          ]
        }
      ],
      "source": [
        "! tar -xvf /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/images/ShelfImages.tar.gz.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d535_XKYMvPI"
      },
      "source": [
        "# Now create the following directories inside /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection\n",
        "\n",
        "# annotations\n",
        "# exported_models\n",
        "# models\n",
        "# pre_trained_models\n",
        "\n",
        "# Now, please remember that if you are going to use Tensorflow 2 Object Detection API to detect objects in images of some other dataset then you have to create a new directory inside /content/drive/MyDrive/tensorflow_od_api/workspace:\n",
        "\n",
        "# For Example, /content/drive/MyDrive/tensorflow_od_api/workspace/ex_dark\n",
        "\n",
        "# and the rest of the directory struture will remain the same. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY02tirT48T8",
        "outputId": "8f753d13-1e37-4146-8ccc-0ad84e0762fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9gMEuFt5ASF",
        "outputId": "284dd236-3f49-46ce-81df-dba6ccc4cd25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘annotations’: File exists\n",
            "mkdir: cannot create directory ‘exported_models’: File exists\n",
            "mkdir: cannot create directory ‘models’: File exists\n",
            "mkdir: cannot create directory ‘pre_trained_models’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir annotations\n",
        "! mkdir exported_models\n",
        "! mkdir models\n",
        "! mkdir pre_trained_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZUPCO0U5YDp"
      },
      "source": [
        "# Every single directory has some purpose which will be discussing about later on. So, right now we have following directories inside /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection \n",
        "\n",
        "# annotations\n",
        "# exported_models\n",
        "# images\n",
        "# models\n",
        "# pre_trained_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjpqVKX15wS2"
      },
      "source": [
        "# Let's now download the annotations of our Shelf Objects Images dataset in the annotations directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JGJGYLEMswP",
        "outputId": "140c99b8-37ec-4873-b8f5-4db530c2fc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1X_o4VrSs06",
        "outputId": "49483c5b-d75b-4f44-c488-27c59e6cd44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'grocerydataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/gulvarol/grocerydataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjr6K2GT9-Rd",
        "outputId": "8d07537e-e8d5-43db-eea6-bad4bdf7f0f3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.62\n",
            "Uninstalling opencv-python-headless-4.5.5.62:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.62.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-64ac49e1.so.58.91.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-4b79e479.so.58.45.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-805734e8.so.56.51.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-018b8c17.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-ce838cd1.so.15.13.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-6082116c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-83ce3247.so.3.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-7e960168.so.5.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-392cd848.so.6.4.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (y/n)? "
          ]
        }
      ],
      "source": [
        "! python -m pip uninstall opencv-python-headless==4.5.5.62\n",
        "! python -m pip install opencv-python-headless==4.1.2.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHX2RyegSwBb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util, label_map_util\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEiOd2PupBY-"
      },
      "outputs": [],
      "source": [
        "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3rmIHd0CgEH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RvR46kub1sw"
      },
      "source": [
        "# Now, let's create our label map file. But the question arrises is what is label map file ? Label map file will consist of dictionaries for different classes of objects which can be detected in an image. The extension of this file is .pbtxt. Each dictionary will consist of two key value pairs, where first key value pair maps the 'id' variable to the class label of the object and the second key value pair maps the 'name' variable to the name of the object. A sample of a dictionary for an object in label map looks like this: \n",
        "\n",
        "# item {\n",
        "#     id: 1\n",
        "#     name: \"Category 1 Object\"\n",
        "# }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDXIPOVvee05"
      },
      "source": [
        "# As there are 11 different objects in our shelf images dataset, therefore there will be 11 such dictionaries written in this label_map.pbtxt file. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7q-0FcofCME"
      },
      "source": [
        "# This label_map.pbtxt file will be written inside the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuJsQDt9gTVY"
      },
      "source": [
        "# We have created the label_map.pbtxt file and written it inside the above mentioned directory. Now, let's load this file and fetch the dictionary from the file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9zX8yjTTJy4"
      },
      "outputs": [],
      "source": [
        "label_map = label_map_util.load_labelmap(\"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations/label_map.pbtxt\")\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucXrbJrIg-Nt"
      },
      "outputs": [],
      "source": [
        "label_map_dict_copy = dict()\n",
        "\n",
        "for k,v in label_map_dict.items():\n",
        "  label_map_dict_copy[v] = k\n",
        "\n",
        "label_map_dict = label_map_dict_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4RPqrovhDvw"
      },
      "outputs": [],
      "source": [
        "label_map_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W63QEb7Zhpw1"
      },
      "source": [
        "# Let's navigate back to the root directory of google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfo2IPNLhfT_"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jFfMO-Zh1ya"
      },
      "source": [
        "# Let's write some functions to create .tfrecord files to store our examples in the form of images as well as it's ground truth labels in the form of ground truth bounding boxes as well as ground truth class labels. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQa3eJHXhyzq"
      },
      "outputs": [],
      "source": [
        "# we r creating a function ---spliting function  whick makes groups of images(283)\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)] # we r doing list compresshion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIHXM87tifaB"
      },
      "outputs": [],
      "source": [
        "# this fun. will create tenserflow examples\n",
        "# and call 283 tyms of every grp...\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid: # here we r reading file in binarry format\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)  # image pixels encode into bytes\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8') # we converted our string fine name into utf8 \n",
        "    image_format = b'jpg'\n",
        "    xmins = []                                   # and  these details are compulsory...\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []                                # from here\n",
        "\n",
        "    for index, row in group.object.iterrows():                                  #\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(label_map_dict[row['gt_labels']].encode('utf8'))\n",
        "        classes.append(row['gt_labels'])\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),                       #  These info. are mandatory \n",
        "        'image/source_id': dataset_util.bytes_feature(filename),                        \n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),    # \n",
        "    }))\n",
        "    return tf_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY7KqjKfimOU"
      },
      "outputs": [],
      "source": [
        "# making 2 tf-records writters\n",
        "# they will write the data into tf-record files  \n",
        "training_data_writer = (tf.python_io.TFRecordWriter(path=\"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations/training_imgs.record\"))\n",
        "testing_data_writer = (tf.python_io.TFRecordWriter(path=\"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations/testing_imgs.record\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcAbjq2bjzZO"
      },
      "outputs": [],
      "source": [
        "annotations_df = pd.read_csv(\"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations/grocerydataset/annotations.csv\",\n",
        "                             header=None, names=[\"file_name\",\"xmin\",\"ymin\",\"xmax\",\"ymax\",\"gt_labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTKJrVagkezV"
      },
      "outputs": [],
      "source": [
        "annotations_df['gt_labels'] = annotations_df['gt_labels'].apply(lambda x: x+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P2TUQTRkkU4"
      },
      "outputs": [],
      "source": [
        "annotations_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zDGkiVGkoea"
      },
      "outputs": [],
      "source": [
        "different_classes = annotations_df['gt_labels'].unique()\n",
        "print(different_classes)\n",
        "print(len(different_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzOBNMiPnJEG"
      },
      "source": [
        "# Let's determine all the file names inside the testing folder of our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4FeAEErmzKB"
      },
      "outputs": [],
      "source": [
        "testing_imgs = os.listdir(\"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/images/ShelfImages/test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLbm58mJnUMk"
      },
      "source": [
        "# As our dataset annotations consist of annotations of all the training as well as testing images, therefore it becomes important to seperate out annotations of training as well as testing images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoJiinwNkyi_"
      },
      "outputs": [],
      "source": [
        "training_data_annotations = list()\n",
        "testing_data_annotations = list()\n",
        "\n",
        "for i in range(len(annotations_df)):\n",
        "\n",
        "  if annotations_df.iloc[i,0] in testing_imgs:\n",
        "    testing_data_annotations.append(list(annotations_df.iloc[i,:]))\n",
        "  else:\n",
        "    training_data_annotations.append(list(annotations_df.iloc[i,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMzWF6zJnD_U"
      },
      "outputs": [],
      "source": [
        "training_data_annotations_df = pd.DataFrame(data=training_data_annotations,columns=annotations_df.columns)\n",
        "testing_data_annotations_df = pd.DataFrame(data=testing_data_annotations,columns=annotations_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYzUcycynqLh"
      },
      "outputs": [],
      "source": [
        "training_data_annotations_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xreqeq1en0QG"
      },
      "outputs": [],
      "source": [
        "testing_data_annotations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt0mlp0Hn7fD"
      },
      "source": [
        "# We have created all the functions to create .tfrecord files as well as also create seperate training as well as testing data annotations. Now, let's start the procedure to create .tfrecord files using the above functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkiPJvf5oUQX"
      },
      "source": [
        "# Let's create training as well as testing examples. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AysxTMM4n3PH"
      },
      "outputs": [],
      "source": [
        "grouped_training_data = split(df=training_data_annotations_df,group=\"file_name\")\n",
        "grouped_testing_data = split(df=testing_data_annotations_df,group=\"file_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlMqo9o5obvr"
      },
      "outputs": [],
      "source": [
        "training_data_base_path = \"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/images/ShelfImages/train\"\n",
        "testing_data_base_path = \"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/images/ShelfImages/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvwX7n_8oo9T"
      },
      "outputs": [],
      "source": [
        "for single_img_group in grouped_training_data:\n",
        "\n",
        "  tf_example = create_tf_example(group=single_img_group,path=training_data_base_path)\n",
        "  training_data_writer.write(record=tf_example.SerializeToString())\n",
        "\n",
        "training_data_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW4OOkJ4pmiJ"
      },
      "outputs": [],
      "source": [
        "for single_img_group in grouped_testing_data:\n",
        "\n",
        "  tf_example = create_tf_example(group=single_img_group,path=testing_data_base_path)\n",
        "  testing_data_writer.write(record=tf_example.SerializeToString())\n",
        "\n",
        "testing_data_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjvLczDkqrhX"
      },
      "outputs": [],
      "source": [
        "images_dataset = tf.data.TFRecordDataset(\"/content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/annotations/training_imgs.record\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anqG-lEXrIkW"
      },
      "outputs": [],
      "source": [
        "out_img_features = {\n",
        "        'image/height': tf.io.FixedLenFeature(shape=[],dtype=tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature(shape=[],dtype=tf.int64),\n",
        "        'image/filename': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/source_id': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/encoded': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/class/text': tf.io.FixedLenSequenceFeature(shape=[],dtype=tf.string,allow_missing=True),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(dtype=tf.int64),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDyBaI5erNlY"
      },
      "outputs": [],
      "source": [
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(serialized=example_proto,features=out_img_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oimick7yrS-M"
      },
      "outputs": [],
      "source": [
        "import IPython.display as display\n",
        "\n",
        "parsed_image_dataset = images_dataset.map(parse_image)\n",
        "counter = 0\n",
        "\n",
        "for image_out_features in parsed_image_dataset:\n",
        "\n",
        "  if counter == 2:\n",
        "    break\n",
        "\n",
        "  print(image_out_features[\"image/height\"])\n",
        "  print(image_out_features[\"image/width\"])\n",
        "  print(image_out_features[\"image/filename\"])\n",
        "  print(image_out_features[\"image/source_id\"])\n",
        "  print(image_out_features[\"image/format\"])\n",
        "  print(image_out_features[\"image/object/bbox/xmin\"])\n",
        "  print(image_out_features[\"image/object/bbox/xmax\"])\n",
        "  print(image_out_features[\"image/object/bbox/ymin\"])\n",
        "  print(image_out_features[\"image/object/bbox/ymax\"])\n",
        "  print(image_out_features[\"image/object/class/text\"])\n",
        "  print(image_out_features[\"image/object/class/label\"])\n",
        "\n",
        "  image_out = image_out_features[\"image/encoded\"].numpy()\n",
        "  display.display(display.Image(data=image_out))\n",
        "\n",
        "  counter = counter + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZxSTzL8r0mO"
      },
      "source": [
        "# Now, we should train our object detection neural network and the neural network which we have chosen from Tensorflow Object Detection Zoo, is: \n",
        "\n",
        "# ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Therefore, we are going to download the zip file of this model to /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/pre_trained_models and fine tune it on our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSx92Eh_roYH"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/pre_trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIwJ1_xFtTKw"
      },
      "outputs": [],
      "source": [
        "! wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlbPuOWltfw4"
      },
      "source": [
        "# Let's now unzip this file at the same location. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Juu_uetZnz"
      },
      "outputs": [],
      "source": [
        "! tar -xvf /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/pre_trained_models/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axYa-j73_YNl"
      },
      "source": [
        "# Now, suppose we wish to use some other pre-trained model to train our object detector on the same dataset then we can download other pre-trained model's tarbar files into the \"pre_trained_models\" directory and untar it here only.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h4aMBg-ABDT"
      },
      "source": [
        "# Now, let's navigate to the /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models and create a new directory for our training job for fine tuning our currently downloaded architecture of SSD. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzsvZQ7XAVcm"
      },
      "source": [
        "# Let's first navigate to the above directory and create a seperate directory for our training job inside the above mentione directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JWWoR29tphr"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT5vAagpAjpc"
      },
      "outputs": [],
      "source": [
        "! mkdir resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWl4AF49A6Kp"
      },
      "source": [
        "# Inside the above created directory, we have to copy the pipeline configuration file (pipeline.config) of the downloaded model inside /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/pre_trained_models/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8\n",
        "\n",
        "# to \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models/resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUw2PJBFA3X3"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/pre_trained_models/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8/pipeline.config /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models/resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV3SNTIzC0KZ"
      },
      "source": [
        "# Now, let's modify our copied pipeline.config file inside /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models/resnet50_v1_ssd_fpn_1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22giBuq7DwrB"
      },
      "source": [
        "# And change the following variables in pipeline.config according to your desired configuration:\n",
        "\n",
        "# (line 3) num_classes: <Total number of classes of different objects in our dataset>\n",
        "\n",
        "# (line 131) batch_size: <Our desired batch size on which we want to fine tune our pre-trained network on our dataset, if we have high end GPU and good amount of memory then keep it to the default value of 8, otherwise reduce it. We will set it to 4> \n",
        "\n",
        "# (line 161) fine_tune_checkpoint: <path of the directory where pre-trained weights of our Neural Network are present in the form of checkpoints and they are going to be fine tuned on our dataset by further training our network on our desired dataset> \n",
        "\n",
        "# (line 167) fine_tune_checkpoint_type: <\"detection\">\n",
        "\n",
        "# (line 168) use_bfloat16: <Set this variable's value to false if not training on a TPU>\n",
        "\n",
        "# (line 172) label_map_path: <path of the directory where label_map.pbtxt file is written>\n",
        "\n",
        "# (line 174) input_path: <path of the directory where TFrecord file of the training data is written>\n",
        "\n",
        "# (line 178) metrics_set: <\"coco_detection_metrics\">\n",
        "\n",
        "# (line 179) use_moving_averages: <\"false\">\n",
        "\n",
        "# (line 182) label_map_path: <path of the directory where label_map.pbtxt file is written>\n",
        "\n",
        "# (line 186) input_path: <path of the directory where TFrecord file of the testing data is written>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftmGKTJtPDK4"
      },
      "source": [
        "# Let's change the directory to root directory of our training configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zvZxxz_Crqc"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58LI8_4PU1L"
      },
      "source": [
        "# Let's copy the file named \"model_main_tf2.py\" from /content/drive/MyDrive/tensorflow_od_api/models/research/object_detection/model_main_tf2.py \n",
        "\n",
        "# to \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection\n",
        "\n",
        "# because now we need this script to fine tune our pre-trained neural network on our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_BqIwnYQAAn"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/tensorflow_od_api/models/research/object_detection/model_main_tf2.py /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDgTkzdTu-RQ"
      },
      "outputs": [],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX7nTE4OvXQd"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Xyg_LyPN6t"
      },
      "outputs": [],
      "source": [
        "! python model_main_tf2.py --model_dir=models/resnet50_v1_ssd_fpn_1024 --pipeline_config_path=models/resnet50_v1_ssd_fpn_1024/pipeline.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxxaSbHih5Ee"
      },
      "source": [
        "# As we have already trained our model and the trained parameters of our model have been saved in the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/models/resnet50_v1_ssd_fpn_1024/train\n",
        "\n",
        "# Now, we should use these trained parameters to perform inference on our unseen data. \n",
        "\n",
        "# Now, in order to do that first we have to export our trained model with trained weights. For that, we have to export our model using a script called exporter_main_v2.py which is located at the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/models/research/object_detection/exporter_main_v2.py\n",
        "\n",
        "# We have to now copy this script from the above location and paste it into the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection\n",
        "\n",
        "# and then run this script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz7Z3JUiQ6ed"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/tensorflow_od_api/models/research/object_detection/exporter_main_v2.py /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awuoSchnkmAA"
      },
      "outputs": [],
      "source": [
        "cd /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-FbCCtxk1-p"
      },
      "source": [
        "# Now, since we have copied the script, let's run the script to export our trained model to the following directory: \n",
        "\n",
        "# /content/drive/MyDrive/tensorflow_od_api/workspace/shelf_objects_detection/exported_models/first_training_instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi-IXmLfkvc0"
      },
      "outputs": [],
      "source": [
        "!python ./exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/resnet50_v1_ssd_fpn_1024/pipeline.config --trained_checkpoint_dir ./models/resnet50_v1_ssd_fpn_1024 --output_directory ./exported_models/first_training_instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwm7BIZ1mjeX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops\n",
        "from object_detection.utils import visualization_utils as viz\n",
        "from object_detection.utils.label_map_util import create_category_index_from_labelmap\n",
        "import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLtsSG7Lpvty"
      },
      "outputs": [],
      "source": [
        "def load_image(path):\n",
        "  image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(image_data))\n",
        "  width, height = image.size\n",
        "  shape = (height, width, 3)\n",
        "  image = np.array(image.getdata())\n",
        "  image = image.reshape(shape).astype('uint8')\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1YpBYw5sU8S"
      },
      "outputs": [],
      "source": [
        "def infer_image(net, image):\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  result = net(input_tensor)\n",
        "  num_detections = int(result.pop('num_detections'))\n",
        "  result = {key: value[0, :num_detections].numpy() for key, value in result.items()}\n",
        "  result['num_detections'] = num_detections\n",
        "  result['detection_classes'] = result['detection_classes'].astype('int64')\n",
        "  if 'detection_masks' in result:\n",
        "    detection_masks_reframed = ops.reframe_box_masks_to_image_masks(result['detection_masks'],result['detection_boxes'],image.shape[0],image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,tf.uint8)\n",
        "    result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzcYF-jIsdD2"
      },
      "outputs": [],
      "source": [
        "labels_path = \"./annotations/label_map.pbtxt\"\n",
        "category_idx = create_category_index_from_labelmap(labels_path,use_display_name=True)\n",
        "model_path = \"./exported_models/first_training_instance/saved_model\"\n",
        "model = tf.saved_model.load(model_path)\n",
        "test_images = list(glob.glob(\"./images/ShelfImages/test/*.JPG\"))\n",
        "random.shuffle(test_images)\n",
        "test_images = test_images[:16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x-09wX0tC-g"
      },
      "outputs": [],
      "source": [
        "for image_path in test_images:\n",
        "  image = load_image(image_path)\n",
        "  result = infer_image(model, image)\n",
        "  masks = result.get('detection_masks_reframed',None)\n",
        "  viz.visualize_boxes_and_labels_on_image_array(image,result['detection_boxes'],result['detection_classes'],\n",
        "                                                result['detection_scores'],category_idx,instance_masks=masks,\n",
        "                                                use_normalized_coordinates=True,line_thickness=5)\n",
        "  plt.figure(figsize=(24,24))\n",
        "  plt.imshow(image)\n",
        "  plt.savefig(f'detections_{image_path.split(\"/\")[-1]}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Completely_Commented_Object_Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}